{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo Location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports\n",
    "2. Paths\n",
    "3. Load and transform images\n",
    "4. Create and train model\n",
    "5. Extract image meta data\n",
    "6. Create dataframe\n",
    "7. Load to csv-file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "import tensorflow as tf                \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow.keras.utils as image2\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Input\n",
    "from PIL import Image\n",
    "import exifread\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_DIR_PATH = os.getcwd()\n",
    "\n",
    "# Training paths\n",
    "seg_train_path = CURR_DIR_PATH + \"//data//seg_train//seg_train\"\n",
    "\n",
    "train_forest_path = seg_train_path + \"//forest\"\n",
    "train_buildings_path = seg_train_path + \"//buildings\"\n",
    "train_glacier_path = seg_train_path + \"//glacier\"\n",
    "train_mountain_path = seg_train_path + \"//mountain\"\n",
    "train_sea_path = seg_train_path + \"//sea\"\n",
    "train_street_path = seg_train_path + \"//street\"\n",
    "\n",
    "# Test paths\n",
    "seg_test_path = CURR_DIR_PATH + \"//data//seg_test//seg_test\"\n",
    "\n",
    "test_forest_path = seg_test_path + \"//forest\"\n",
    "test_buildings_path = seg_test_path + \"//buildings\"\n",
    "test_glacier_path = seg_test_path + \"//glacier\"\n",
    "test_mountain_path = seg_test_path + \"//mountain\"\n",
    "test_sea_path = seg_test_path + \"//sea\"\n",
    "test_street_path = seg_test_path + \"//street\"\n",
    "\n",
    "# Prediction path\n",
    "seg_pred_path = CURR_DIR_PATH + \"//data//seg_pred//seg_pred\"\n",
    "\n",
    "# Our path\n",
    "seg_our_path = CURR_DIR_PATH + \"//data//seg_our//seg_our\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and transform images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label = -1\n",
    "    for path in paths:\n",
    "        label = label+1\n",
    "        for file in tqdm(os.listdir(path)):\n",
    "            image_path = os.path.join(path, file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image,(150, 150)) \n",
    "            image = image/ 255.0\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')\n",
    "\n",
    "    output = (images,labels)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2191/2191 [00:09<00:00, 226.90it/s]\n",
      "100%|██████████| 2271/2271 [00:10<00:00, 216.18it/s]\n",
      "100%|██████████| 2404/2404 [00:04<00:00, 493.44it/s]\n",
      "100%|██████████| 2512/2512 [00:04<00:00, 614.90it/s]\n",
      "100%|██████████| 2274/2274 [00:03<00:00, 615.99it/s]\n",
      "100%|██████████| 2382/2382 [00:03<00:00, 601.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 14034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437/437 [00:00<00:00, 636.25it/s]\n",
      "100%|██████████| 474/474 [00:00<00:00, 604.94it/s]\n",
      "100%|██████████| 553/553 [00:00<00:00, 651.61it/s]\n",
      "100%|██████████| 525/525 [00:00<00:00, 644.35it/s]\n",
      "100%|██████████| 510/510 [00:00<00:00, 670.82it/s]\n",
      "100%|██████████| 501/501 [00:00<00:00, 644.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing images: 3000\n"
     ]
    }
   ],
   "source": [
    "train_paths = [train_buildings_path, train_forest_path, train_glacier_path, train_mountain_path, train_sea_path, train_street_path]\n",
    "test_paths = [test_buildings_path, test_forest_path, test_glacier_path, test_mountain_path, test_sea_path, test_street_path]\n",
    "train_images, train_labels= load_data(train_paths)\n",
    "print (f\"Number of training images: {train_labels.shape[0]}\")\n",
    "test_images, test_labels = load_data(test_paths)\n",
    "print (f\"Number of testing images: {test_labels.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "88/88 [==============================] - 102s 1s/step - loss: 1.2872 - accuracy: 0.5353 - val_loss: 0.9054 - val_accuracy: 0.6477\n",
      "Epoch 2/40\n",
      "88/88 [==============================] - 102s 1s/step - loss: 0.8164 - accuracy: 0.6987 - val_loss: 0.7664 - val_accuracy: 0.7228\n",
      "Epoch 3/40\n",
      "88/88 [==============================] - 102s 1s/step - loss: 0.6702 - accuracy: 0.7588 - val_loss: 0.6678 - val_accuracy: 0.7606\n",
      "Epoch 4/40\n",
      "88/88 [==============================] - 104s 1s/step - loss: 0.5628 - accuracy: 0.8039 - val_loss: 0.7273 - val_accuracy: 0.7335\n",
      "Epoch 5/40\n",
      "88/88 [==============================] - 103s 1s/step - loss: 0.4414 - accuracy: 0.8464 - val_loss: 0.6017 - val_accuracy: 0.7873\n",
      "Epoch 6/40\n",
      "88/88 [==============================] - 119s 1s/step - loss: 0.3241 - accuracy: 0.8933 - val_loss: 0.6460 - val_accuracy: 0.7866\n",
      "Epoch 7/40\n",
      "88/88 [==============================] - 127s 1s/step - loss: 0.2434 - accuracy: 0.9225 - val_loss: 0.6962 - val_accuracy: 0.7870\n",
      "Epoch 8/40\n",
      "88/88 [==============================] - 108s 1s/step - loss: 0.1664 - accuracy: 0.9507 - val_loss: 0.7379 - val_accuracy: 0.7905\n",
      "Epoch 9/40\n",
      "88/88 [==============================] - 106s 1s/step - loss: 0.1069 - accuracy: 0.9721 - val_loss: 0.8268 - val_accuracy: 0.7570\n",
      "Epoch 10/40\n",
      "88/88 [==============================] - 106s 1s/step - loss: 0.0764 - accuracy: 0.9806 - val_loss: 0.8525 - val_accuracy: 0.7770\n",
      "Epoch 11/40\n",
      "88/88 [==============================] - 109s 1s/step - loss: 0.0524 - accuracy: 0.9880 - val_loss: 0.9130 - val_accuracy: 0.7845\n",
      "Epoch 12/40\n",
      "88/88 [==============================] - 128s 1s/step - loss: 0.0446 - accuracy: 0.9911 - val_loss: 1.0279 - val_accuracy: 0.7748\n",
      "Epoch 13/40\n",
      "88/88 [==============================] - 162s 2s/step - loss: 0.0608 - accuracy: 0.9831 - val_loss: 0.8995 - val_accuracy: 0.7713\n",
      "Epoch 14/40\n",
      "88/88 [==============================] - 161s 2s/step - loss: 0.0499 - accuracy: 0.9890 - val_loss: 1.0169 - val_accuracy: 0.7841\n",
      "Epoch 15/40\n",
      "88/88 [==============================] - 161s 2s/step - loss: 0.0274 - accuracy: 0.9949 - val_loss: 1.1470 - val_accuracy: 0.7795\n",
      "Epoch 16/40\n",
      "88/88 [==============================] - 161s 2s/step - loss: 0.0210 - accuracy: 0.9971 - val_loss: 1.1229 - val_accuracy: 0.7873\n",
      "Epoch 17/40\n",
      "88/88 [==============================] - 161s 2s/step - loss: 0.0191 - accuracy: 0.9971 - val_loss: 1.1655 - val_accuracy: 0.7809\n",
      "Epoch 18/40\n",
      "88/88 [==============================] - 161s 2s/step - loss: 0.0297 - accuracy: 0.9926 - val_loss: 1.1398 - val_accuracy: 0.7816\n",
      "Epoch 19/40\n",
      "88/88 [==============================] - 160s 2s/step - loss: 0.0177 - accuracy: 0.9971 - val_loss: 1.1955 - val_accuracy: 0.7855\n",
      "Epoch 20/40\n",
      "88/88 [==============================] - 162s 2s/step - loss: 0.0127 - accuracy: 0.9984 - val_loss: 1.2054 - val_accuracy: 0.7884\n",
      "Epoch 21/40\n",
      "88/88 [==============================] - 134s 2s/step - loss: 0.0100 - accuracy: 0.9988 - val_loss: 1.3213 - val_accuracy: 0.7816\n",
      "Epoch 22/40\n",
      "88/88 [==============================] - 134s 2s/step - loss: 0.0129 - accuracy: 0.9987 - val_loss: 1.3565 - val_accuracy: 0.7741\n",
      "Epoch 23/40\n",
      "88/88 [==============================] - 134s 2s/step - loss: 0.0110 - accuracy: 0.9989 - val_loss: 1.2786 - val_accuracy: 0.7880\n",
      "Epoch 24/40\n",
      "88/88 [==============================] - 133s 2s/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 1.2858 - val_accuracy: 0.7873\n",
      "Epoch 25/40\n",
      "88/88 [==============================] - 138s 2s/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 1.2926 - val_accuracy: 0.7895\n",
      "Epoch 26/40\n",
      "88/88 [==============================] - 154s 2s/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 1.2238 - val_accuracy: 0.7859\n",
      "Epoch 27/40\n",
      "88/88 [==============================] - 145s 2s/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 1.3035 - val_accuracy: 0.7791\n",
      "Epoch 28/40\n",
      "88/88 [==============================] - 134s 2s/step - loss: 0.0129 - accuracy: 0.9989 - val_loss: 1.3462 - val_accuracy: 0.7816\n",
      "Epoch 29/40\n",
      "88/88 [==============================] - 134s 2s/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 1.3358 - val_accuracy: 0.7827\n",
      "Epoch 30/40\n",
      "88/88 [==============================] - 133s 2s/step - loss: 0.0131 - accuracy: 0.9990 - val_loss: 1.3670 - val_accuracy: 0.7731\n",
      "Epoch 31/40\n",
      "88/88 [==============================] - 133s 2s/step - loss: 0.0108 - accuracy: 0.9989 - val_loss: 1.2656 - val_accuracy: 0.7870\n",
      "Epoch 32/40\n",
      "88/88 [==============================] - 133s 2s/step - loss: 0.0120 - accuracy: 0.9991 - val_loss: 1.3381 - val_accuracy: 0.7695\n",
      "Epoch 33/40\n",
      "88/88 [==============================] - 134s 2s/step - loss: 0.0131 - accuracy: 0.9985 - val_loss: 1.3109 - val_accuracy: 0.7802\n",
      "Epoch 34/40\n",
      "88/88 [==============================] - 133s 2s/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 1.2666 - val_accuracy: 0.7624\n",
      "Epoch 35/40\n",
      "88/88 [==============================] - 133s 2s/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 1.3414 - val_accuracy: 0.7816\n",
      "Epoch 36/40\n",
      "88/88 [==============================] - 133s 2s/step - loss: 0.0678 - accuracy: 0.9804 - val_loss: 1.3700 - val_accuracy: 0.7496\n",
      "Epoch 37/40\n",
      "88/88 [==============================] - 149s 2s/step - loss: 0.0198 - accuracy: 0.9955 - val_loss: 1.4672 - val_accuracy: 0.7816\n",
      "Epoch 38/40\n",
      "88/88 [==============================] - 160s 2s/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 1.5605 - val_accuracy: 0.7674\n",
      "Epoch 39/40\n",
      "88/88 [==============================] - 159s 2s/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 1.5106 - val_accuracy: 0.7748\n",
      "Epoch 40/40\n",
      "88/88 [==============================] - 160s 2s/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 1.4759 - val_accuracy: 0.7855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=128, epochs=40, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gps_info(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        tags = exifread.process_file(image_file)\n",
    "        lat_deg = tags.get('GPS GPSLatitude', None)\n",
    "        lat_ref = tags.get('GPS GPSLatitudeRef', None)\n",
    "        long_deg = tags.get('GPS GPSLongitude', None)\n",
    "        long_ref = tags.get('GPS GPSLongitudeRef', None)\n",
    "        timestamp = tags.get('EXIF DateTimeOriginal', None)\n",
    "        latitude = convert_to_degrees(lat_deg, lat_ref)\n",
    "        longitude = convert_to_degrees(long_deg, long_ref)\n",
    "        return (latitude, longitude, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_degrees(coordinate, ref):\n",
    "    coordinate = list(coordinate.values)\n",
    "    d = float(coordinate[0].num) / coordinate[0].den\n",
    "    m = float(coordinate[1].num) / coordinate[1].den\n",
    "    s = float(coordinate[2].num) / coordinate[2].den\n",
    "    result = d + (m / 60.0) + (s / 3600.0)\n",
    "    if str(ref) == 'S' or str(ref) == 'W':\n",
    "        result *= -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_name(latitude, longitude):\n",
    "    url = f\"https://nominatim.openstreetmap.org/reverse?format=json&lat={latitude}&lon={longitude}\"\n",
    "    response = requests.get(url)\n",
    "    location_name = response.json().get('address').get('town') or response.json().get('address').get('city')\n",
    "    country = response.json().get('address').get('country')\n",
    "    return location_name, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(path):\n",
    "    img = cv2.imread(path)\n",
    "    test1_proc = image2.load_img(path , target_size=(150,150))\n",
    "    test1_proc_1 = image2.img_to_array(test1_proc)\n",
    "    t1 = np.expand_dims(test1_proc ,axis=0)\n",
    "    t1 = t1/255\n",
    "    pred_classes = model.predict(t1)\n",
    "    pred = np.argmax(pred_classes ,axis=1)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    pic = Image.open(path) \n",
    "    plt.xlabel(\"Original Image\")\n",
    "    plt.imshow(pic)\n",
    "    \n",
    "    \n",
    "    plt.subplot(122)\n",
    "\n",
    "    s1 = pd.Series(pred_classes.ravel() , index = category_label)\n",
    "    s1.plot(kind = 'bar' ,figsize = (10,5))\n",
    "    plt.xlabel(\"prediction\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract image meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Possibly corrupted field Tag 0x001A in MakerNote IFD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Possibly corrupted field Tag 0x001A in MakerNote IFD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "longitudes = []\n",
    "latitudes = []\n",
    "timestamps = []\n",
    "location_names = []\n",
    "countries = []\n",
    "categories = []\n",
    "file_names = []\n",
    "category_label=['buildings','forest', 'glacier','mountain','sea','street']\n",
    "\n",
    "\n",
    "for file in os.listdir(seg_our_path):\n",
    "    image_path = (os.path.join(seg_our_path, file))\n",
    "    image_paths.append(image_path)\n",
    "    img = cv2.imread(image_path)\n",
    "    test1_proc = image2.load_img(image_path , target_size=(150,150))\n",
    "    test1_proc_1 = image2.img_to_array(test1_proc)\n",
    "    t1 = np.expand_dims(test1_proc ,axis=0)\n",
    "    t1 = t1/255\n",
    "    pred_classes = model.predict(t1)\n",
    "    pred = np.argmax(pred_classes ,axis=1)\n",
    "    for i in range(len(category_label)):\n",
    "        if pred == i:\n",
    "            category = category_label[i]\n",
    "    location = extract_gps_info(image_path)\n",
    "    if location:\n",
    "\n",
    "        longitude = location[1]\n",
    "        latitude = location[0]\n",
    "        location_name, country = get_location_name(location[0], location[1])\n",
    "        timestamp = location[2]\n",
    "        longitudes.append(longitude)\n",
    "        latitudes.append(latitude)\n",
    "        timestamps.append(timestamp)\n",
    "        location_names.append(location_name)\n",
    "        countries.append(country)\n",
    "        file_names.append(file)\n",
    "        categories.append(category)\n",
    "    else:\n",
    "        print(\"\\nNo geolocation information found in the photo.\" + file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name   latitude  longitude         country        location  \\\n",
      "0            A.jpg  50.661414  -1.579089  United Kingdom            None   \n",
      "1            B.jpg  51.171403  -0.841544  United Kingdom  East Hampshire   \n",
      "2            C.JPG  59.345469  18.032781         Sverige       Stockholm   \n",
      "3            D.jpg  50.668992  -1.569306  United Kingdom            None   \n",
      "4            E.jpg  68.339408  14.906944           Norge            None   \n",
      "..             ...        ...        ...             ...             ...   \n",
      "96   IMG_E2798.JPG  59.347256  18.031139         Sverige       Stockholm   \n",
      "97   IMG_E2799.JPG  59.347256  18.031139         Sverige       Stockholm   \n",
      "98      italia.JPG  45.441344  12.323050          Italia          Mestre   \n",
      "99       norge.JPG  59.033683   6.593531           Norge            None   \n",
      "100       test.JPG  59.346808  18.031856         Sverige       Stockholm   \n",
      "\n",
      "                    time classification  \n",
      "0    2022:07:29 14:39:33        glacier  \n",
      "1    2022:08:06 12:11:15         forest  \n",
      "2    2023:02:09 12:34:39      buildings  \n",
      "3    2022:07:29 13:20:42       mountain  \n",
      "4    2022:05:19 11:13:39        glacier  \n",
      "..                   ...            ...  \n",
      "96   2023:02:13 10:57:18            sea  \n",
      "97   2023:02:13 10:57:26      buildings  \n",
      "98   2021:11:07 10:29:34      buildings  \n",
      "99   2022:08:15 11:04:17      buildings  \n",
      "100  2023:02:15 11:39:55      buildings  \n",
      "\n",
      "[101 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "image_dict = {'name': file_names, 'latitude':latitudes, 'longitude': longitudes, 'country':countries, 'location':location_names, 'time': timestamps, 'classification':categories}\n",
    "image_df = pd.DataFrame(image_dict)\n",
    "\n",
    "print(image_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Load to csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.to_csv('image.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that latitude and longitude are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "-73.985625 40.748419444444444\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "longitudes = []\n",
    "latitudes = []\n",
    "timestamps = []\n",
    "location_names = []\n",
    "countries = []\n",
    "categories = []\n",
    "file_names = []\n",
    "category_label=['buildings','forest', 'glacier','mountain','sea','street']\n",
    "\n",
    "file2 = \"IMG_2064.jpg\"\n",
    "\n",
    "if True:\n",
    "    image_path = (os.path.join(seg_our_path, file2))\n",
    "    image_paths.append(image_path)\n",
    "    img = cv2.imread(image_path)\n",
    "    test1_proc = image2.load_img(image_path , target_size=(150,150))\n",
    "    test1_proc_1 = image2.img_to_array(test1_proc)\n",
    "    t1 = np.expand_dims(test1_proc ,axis=0)\n",
    "    t1 = t1/255\n",
    "    pred_classes = model.predict(t1)\n",
    "    pred = np.argmax(pred_classes ,axis=1)\n",
    "    for i in range(len(category_label)):\n",
    "        if pred == i:\n",
    "            category = category_label[i]\n",
    "    location = extract_gps_info(image_path)\n",
    "    if location:\n",
    "\n",
    "        longitude = location[1]\n",
    "        latitude = location[0]\n",
    "        print(longitude, latitude)\n",
    "        location_name, country = get_location_name(location[0], location[1])\n",
    "        timestamp = location[2]\n",
    "        longitudes.append(longitude)\n",
    "        latitudes.append(latitude)\n",
    "        timestamps.append(timestamp)\n",
    "        location_names.append(location_name)\n",
    "        countries.append(country)\n",
    "        file_names.append(file)\n",
    "        categories.append(category)\n",
    "    else:\n",
    "        print(\"\\nNo geolocation information found in the photo.\" + file2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
