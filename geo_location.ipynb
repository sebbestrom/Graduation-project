{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo Location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports\n",
    "2. Paths\n",
    "3. Load and transform images\n",
    "4. Create and train model\n",
    "5. Extract image meta data\n",
    "6. Create dataframe\n",
    "7. Load to csv-file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "import tensorflow as tf                \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow.keras.utils as image2\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Input\n",
    "from PIL import Image\n",
    "import exifread\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_DIR_PATH = os.getcwd()\n",
    "\n",
    "# Training paths\n",
    "seg_train_path = CURR_DIR_PATH + \"//data//seg_train//seg_train\"\n",
    "\n",
    "train_forest_path = seg_train_path + \"//forest\"\n",
    "train_buildings_path = seg_train_path + \"//buildings\"\n",
    "train_glacier_path = seg_train_path + \"//glacier\"\n",
    "train_mountain_path = seg_train_path + \"//mountain\"\n",
    "train_sea_path = seg_train_path + \"//sea\"\n",
    "train_street_path = seg_train_path + \"//street\"\n",
    "\n",
    "# Test paths\n",
    "seg_test_path = CURR_DIR_PATH + \"//data//seg_test//seg_test\"\n",
    "\n",
    "test_forest_path = seg_test_path + \"//forest\"\n",
    "test_buildings_path = seg_test_path + \"//buildings\"\n",
    "test_glacier_path = seg_test_path + \"//glacier\"\n",
    "test_mountain_path = seg_test_path + \"//mountain\"\n",
    "test_sea_path = seg_test_path + \"//sea\"\n",
    "test_street_path = seg_test_path + \"//street\"\n",
    "\n",
    "# Prediction path\n",
    "seg_pred_path = CURR_DIR_PATH + \"//data//seg_pred//seg_pred\"\n",
    "\n",
    "# Our path\n",
    "seg_our_path = CURR_DIR_PATH + \"//data//seg_our//seg_our\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and transform images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label = -1\n",
    "    for path in paths:\n",
    "        label = label+1\n",
    "        for file in tqdm(os.listdir(path)):\n",
    "            image_path = os.path.join(path, file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image,(150, 150)) \n",
    "            image = image/ 255.0\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')\n",
    "\n",
    "    output = (images,labels)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2191/2191 [00:08<00:00, 268.92it/s]\n",
      "100%|██████████| 2271/2271 [00:08<00:00, 259.08it/s]\n",
      "100%|██████████| 2404/2404 [00:08<00:00, 295.47it/s]\n",
      "100%|██████████| 2512/2512 [00:08<00:00, 303.04it/s]\n",
      "100%|██████████| 2274/2274 [00:07<00:00, 301.45it/s]\n",
      "100%|██████████| 2382/2382 [00:08<00:00, 280.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 14034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437/437 [00:01<00:00, 286.64it/s]\n",
      "100%|██████████| 474/474 [00:01<00:00, 242.70it/s]\n",
      "100%|██████████| 553/553 [00:01<00:00, 287.07it/s]\n",
      "100%|██████████| 525/525 [00:01<00:00, 269.30it/s]\n",
      "100%|██████████| 510/510 [00:01<00:00, 283.81it/s]\n",
      "100%|██████████| 501/501 [00:01<00:00, 277.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing images: 3000\n"
     ]
    }
   ],
   "source": [
    "train_paths = [train_buildings_path, train_forest_path, train_glacier_path, train_mountain_path, train_sea_path, train_street_path]\n",
    "test_paths = [test_buildings_path, test_forest_path, test_glacier_path, test_mountain_path, test_sea_path, test_street_path]\n",
    "train_images, train_labels= load_data(train_paths)\n",
    "print (f\"Number of training images: {train_labels.shape[0]}\")\n",
    "test_images, test_labels = load_data(test_paths)\n",
    "print (f\"Number of testing images: {test_labels.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "88/88 [==============================] - 151s 2s/step - loss: 1.3369 - accuracy: 0.5110 - val_loss: 0.9556 - val_accuracy: 0.6370\n",
      "Epoch 2/40\n",
      "88/88 [==============================] - 148s 2s/step - loss: 0.8154 - accuracy: 0.6953 - val_loss: 0.8189 - val_accuracy: 0.6933\n",
      "Epoch 3/40\n",
      "88/88 [==============================] - 144s 2s/step - loss: 0.6518 - accuracy: 0.7639 - val_loss: 0.6832 - val_accuracy: 0.7535\n",
      "Epoch 4/40\n",
      "88/88 [==============================] - 145s 2s/step - loss: 0.5391 - accuracy: 0.8062 - val_loss: 0.7907 - val_accuracy: 0.7118\n",
      "Epoch 5/40\n",
      "88/88 [==============================] - 140s 2s/step - loss: 0.4227 - accuracy: 0.8549 - val_loss: 0.6753 - val_accuracy: 0.7595\n",
      "Epoch 6/40\n",
      "88/88 [==============================] - 143s 2s/step - loss: 0.3074 - accuracy: 0.9004 - val_loss: 0.6967 - val_accuracy: 0.7613\n",
      "Epoch 7/40\n",
      "88/88 [==============================] - 144s 2s/step - loss: 0.2199 - accuracy: 0.9307 - val_loss: 0.7542 - val_accuracy: 0.7652\n",
      "Epoch 8/40\n",
      "88/88 [==============================] - 146s 2s/step - loss: 0.1657 - accuracy: 0.9499 - val_loss: 0.8124 - val_accuracy: 0.7627\n",
      "Epoch 9/40\n",
      "88/88 [==============================] - 139s 2s/step - loss: 0.1252 - accuracy: 0.9661 - val_loss: 0.8254 - val_accuracy: 0.7745\n",
      "Epoch 10/40\n",
      "88/88 [==============================] - 140s 2s/step - loss: 0.0892 - accuracy: 0.9767 - val_loss: 0.9116 - val_accuracy: 0.7695\n",
      "Epoch 11/40\n",
      "88/88 [==============================] - 151s 2s/step - loss: 0.0591 - accuracy: 0.9870 - val_loss: 1.0436 - val_accuracy: 0.7439\n",
      "Epoch 12/40\n",
      "88/88 [==============================] - 160s 2s/step - loss: 0.0495 - accuracy: 0.9895 - val_loss: 0.9623 - val_accuracy: 0.7681\n",
      "Epoch 13/40\n",
      "88/88 [==============================] - 133s 1s/step - loss: 0.0399 - accuracy: 0.9931 - val_loss: 1.1284 - val_accuracy: 0.7585\n",
      "Epoch 14/40\n",
      "88/88 [==============================] - 108s 1s/step - loss: 0.0314 - accuracy: 0.9941 - val_loss: 1.1861 - val_accuracy: 0.7631\n",
      "Epoch 15/40\n",
      "88/88 [==============================] - 113s 1s/step - loss: 0.0235 - accuracy: 0.9965 - val_loss: 1.1653 - val_accuracy: 0.7602\n",
      "Epoch 16/40\n",
      "88/88 [==============================] - 138s 2s/step - loss: 0.0196 - accuracy: 0.9974 - val_loss: 1.1995 - val_accuracy: 0.7674\n",
      "Epoch 17/40\n",
      "88/88 [==============================] - 111s 1s/step - loss: 0.0189 - accuracy: 0.9976 - val_loss: 1.2321 - val_accuracy: 0.7674\n",
      "Epoch 18/40\n",
      "88/88 [==============================] - 107s 1s/step - loss: 0.0261 - accuracy: 0.9940 - val_loss: 1.3244 - val_accuracy: 0.7474\n",
      "Epoch 19/40\n",
      "88/88 [==============================] - 105s 1s/step - loss: 0.0202 - accuracy: 0.9968 - val_loss: 1.3024 - val_accuracy: 0.7631\n",
      "Epoch 20/40\n",
      "88/88 [==============================] - 106s 1s/step - loss: 0.0135 - accuracy: 0.9984 - val_loss: 1.3204 - val_accuracy: 0.7748\n",
      "Epoch 21/40\n",
      "88/88 [==============================] - 105s 1s/step - loss: 0.0240 - accuracy: 0.9953 - val_loss: 1.3806 - val_accuracy: 0.7574\n",
      "Epoch 22/40\n",
      "88/88 [==============================] - 105s 1s/step - loss: 0.1757 - accuracy: 0.9472 - val_loss: 1.1386 - val_accuracy: 0.7613\n",
      "Epoch 23/40\n",
      "88/88 [==============================] - 105s 1s/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 1.2334 - val_accuracy: 0.7674\n",
      "Epoch 24/40\n",
      "88/88 [==============================] - 105s 1s/step - loss: 0.0110 - accuracy: 0.9986 - val_loss: 1.3577 - val_accuracy: 0.7581\n",
      "Epoch 25/40\n",
      "88/88 [==============================] - 105s 1s/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 1.3821 - val_accuracy: 0.7638\n",
      "Epoch 26/40\n",
      "88/88 [==============================] - 105s 1s/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 1.3826 - val_accuracy: 0.7702\n",
      "Epoch 27/40\n",
      "88/88 [==============================] - 105s 1s/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 1.3508 - val_accuracy: 0.7663\n",
      "Epoch 28/40\n",
      "88/88 [==============================] - 107s 1s/step - loss: 0.0081 - accuracy: 0.9994 - val_loss: 1.4829 - val_accuracy: 0.7652\n",
      "Epoch 29/40\n",
      "88/88 [==============================] - 109s 1s/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 1.4141 - val_accuracy: 0.7574\n",
      "Epoch 30/40\n",
      "88/88 [==============================] - 107s 1s/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 1.4332 - val_accuracy: 0.7659\n",
      "Epoch 31/40\n",
      "88/88 [==============================] - 123s 1s/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 1.4320 - val_accuracy: 0.7756\n",
      "Epoch 32/40\n",
      "88/88 [==============================] - 160s 2s/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 1.4415 - val_accuracy: 0.7699\n",
      "Epoch 33/40\n",
      "88/88 [==============================] - 159s 2s/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 1.4295 - val_accuracy: 0.7724\n",
      "Epoch 34/40\n",
      "88/88 [==============================] - 160s 2s/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 1.4998 - val_accuracy: 0.7574\n",
      "Epoch 35/40\n",
      "88/88 [==============================] - 165s 2s/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 1.4475 - val_accuracy: 0.7752\n",
      "Epoch 36/40\n",
      "88/88 [==============================] - 145s 2s/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 1.5151 - val_accuracy: 0.7642\n",
      "Epoch 37/40\n",
      "88/88 [==============================] - 155s 2s/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 1.4598 - val_accuracy: 0.7706\n",
      "Epoch 38/40\n",
      "88/88 [==============================] - 140s 2s/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 1.5678 - val_accuracy: 0.7549\n",
      "Epoch 39/40\n",
      "88/88 [==============================] - 164s 2s/step - loss: 0.0074 - accuracy: 0.9991 - val_loss: 1.5910 - val_accuracy: 0.7681\n",
      "Epoch 40/40\n",
      "88/88 [==============================] - 144s 2s/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 1.5753 - val_accuracy: 0.7691\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=128, epochs=40, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gps_info(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        tags = exifread.process_file(image_file)\n",
    "        lat_deg = tags.get('GPS GPSLatitude', None)\n",
    "        lat_ref = tags.get('GPS GPSLatitudeRef', None)\n",
    "        long_deg = tags.get('GPS GPSLongitude', None)\n",
    "        long_ref = tags.get('GPS GPSLongitudeRef', None)\n",
    "        timestamp = tags.get('EXIF DateTimeOriginal', None)\n",
    "        latitude = convert_to_degrees(lat_deg, lat_ref)\n",
    "        longitude = convert_to_degrees(long_deg, long_ref)\n",
    "        return (latitude, longitude, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_degrees(coordinate, ref):\n",
    "    coordinate = list(coordinate.values)\n",
    "    d = float(coordinate[0].num) / coordinate[0].den\n",
    "    m = float(coordinate[1].num) / coordinate[1].den\n",
    "    s = float(coordinate[2].num) / coordinate[2].den\n",
    "    result = d + (m / 60.0) + (s / 3600.0)\n",
    "    if str(ref) == 'S' or str(ref) == 'W':\n",
    "        result *= -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_name(latitude, longitude):\n",
    "    url = f\"https://nominatim.openstreetmap.org/reverse?format=json&lat={latitude}&lon={longitude}\"\n",
    "    response = requests.get(url)\n",
    "    location_name = response.json().get('address').get('town') or response.json().get('address').get('city')\n",
    "    country = response.json().get('address').get('country')\n",
    "    return location_name, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(path):\n",
    "    img = cv2.imread(path)\n",
    "    test1_proc = image2.load_img(path , target_size=(150,150))\n",
    "    test1_proc_1 = image2.img_to_array(test1_proc)\n",
    "    t1 = np.expand_dims(test1_proc ,axis=0)\n",
    "    t1 = t1/255\n",
    "    pred_classes = model.predict(t1)\n",
    "    pred = np.argmax(pred_classes ,axis=1)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    pic = Image.open(path) \n",
    "    plt.xlabel(\"Original Image\")\n",
    "    plt.imshow(pic)\n",
    "    \n",
    "    \n",
    "    plt.subplot(122)\n",
    "\n",
    "    s1 = pd.Series(pred_classes.ravel() , index = category_label)\n",
    "    s1.plot(kind = 'bar' ,figsize = (10,5))\n",
    "    plt.xlabel(\"prediction\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract image meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Possibly corrupted field Tag 0x001A in MakerNote IFD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Possibly corrupted field Tag 0x001A in MakerNote IFD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "longitudes = []\n",
    "latitudes = []\n",
    "timestamps = []\n",
    "location_names = []\n",
    "countries = []\n",
    "categories = []\n",
    "file_names = []\n",
    "category_label=['buildings','forest', 'glacier','mountain','sea','street']\n",
    "\n",
    "\n",
    "for file in os.listdir(seg_our_path):\n",
    "    image_path = (os.path.join(seg_our_path, file))\n",
    "    image_paths.append(image_path)\n",
    "    img = cv2.imread(image_path)\n",
    "    test1_proc = image2.load_img(image_path , target_size=(150,150))\n",
    "    test1_proc_1 = image2.img_to_array(test1_proc)\n",
    "    t1 = np.expand_dims(test1_proc ,axis=0)\n",
    "    t1 = t1/255\n",
    "    pred_classes = model.predict(t1)\n",
    "    pred = np.argmax(pred_classes ,axis=1)\n",
    "    for i in range(len(category_label)):\n",
    "        if pred == i:\n",
    "            category = category_label[i]\n",
    "    location = extract_gps_info(image_path)\n",
    "    if location:\n",
    "\n",
    "        longitude = location[1]\n",
    "        latitude = location[0]\n",
    "        location_name, country = get_location_name(location[0], location[1])\n",
    "        timestamp = location[2]\n",
    "        longitudes.append(longitude)\n",
    "        latitudes.append(latitude)\n",
    "        timestamps.append(timestamp)\n",
    "        location_names.append(location_name)\n",
    "        countries.append(country)\n",
    "        file_names.append(file)\n",
    "        categories.append(category)\n",
    "    else:\n",
    "        print(\"\\nNo geolocation information found in the photo.\" + file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name   latitude  longitude          country   location  \\\n",
      "0    IMG-0803.JPG  60.009289  20.182667  Suomi / Finland    Lemland   \n",
      "1    IMG-1018.JPG  60.096786  19.931394  Suomi / Finland  Mariehamn   \n",
      "2    IMG-1260.JPG  59.999133  20.188319  Suomi / Finland    Lemland   \n",
      "3    IMG-1330.jpg  60.050383  20.082594  Suomi / Finland    Lemland   \n",
      "4    IMG-1340.jpg  57.922142  11.754942          Sverige       None   \n",
      "..            ...        ...        ...              ...        ...   \n",
      "95  IMG_E2799.JPG  59.347256  18.031139          Sverige  Stockholm   \n",
      "96     italia.JPG  45.441344  12.323050           Italia     Mestre   \n",
      "97     moskva.JPG  55.752994  37.622097           Россия     Москва   \n",
      "98      norge.JPG  59.033683   6.593531            Norge       None   \n",
      "99      sthlm.JPG  59.345469  18.032781          Sverige  Stockholm   \n",
      "\n",
      "                   time classification  \n",
      "0   2015:08:11 20:49:27            sea  \n",
      "1   2015:10:27 14:39:28         forest  \n",
      "2   2016:10:13 13:16:37         forest  \n",
      "3   2021:07:30 21:12:32         street  \n",
      "4   2021:08:02 15:03:55            sea  \n",
      "..                  ...            ...  \n",
      "95  2023:02:13 10:57:26      buildings  \n",
      "96  2021:11:07 10:29:34      buildings  \n",
      "97  2018:06:25 18:54:01       mountain  \n",
      "98  2022:08:15 11:04:17      buildings  \n",
      "99  2023:02:09 12:34:39      buildings  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "image_dict = {'name': file_names, 'latitude':latitudes, 'longitude': longitudes, 'country':countries, 'location':location_names, 'time': timestamps, 'classification':categories}\n",
    "image_df = pd.DataFrame(image_dict)\n",
    "\n",
    "print(image_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Load to csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.to_csv('image.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that latitude and longitude are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "-73.985625 40.748419444444444\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "longitudes = []\n",
    "latitudes = []\n",
    "timestamps = []\n",
    "location_names = []\n",
    "countries = []\n",
    "categories = []\n",
    "file_names = []\n",
    "category_label=['buildings','forest', 'glacier','mountain','sea','street']\n",
    "\n",
    "file2 = \"IMG_2064.jpg\"\n",
    "\n",
    "if True:\n",
    "    image_path = (os.path.join(seg_our_path, file2))\n",
    "    image_paths.append(image_path)\n",
    "    img = cv2.imread(image_path)\n",
    "    test1_proc = image2.load_img(image_path , target_size=(150,150))\n",
    "    test1_proc_1 = image2.img_to_array(test1_proc)\n",
    "    t1 = np.expand_dims(test1_proc ,axis=0)\n",
    "    t1 = t1/255\n",
    "    pred_classes = model.predict(t1)\n",
    "    pred = np.argmax(pred_classes ,axis=1)\n",
    "    for i in range(len(category_label)):\n",
    "        if pred == i:\n",
    "            category = category_label[i]\n",
    "    location = extract_gps_info(image_path)\n",
    "    if location:\n",
    "\n",
    "        longitude = location[1]\n",
    "        latitude = location[0]\n",
    "        print(longitude, latitude)\n",
    "        location_name, country = get_location_name(location[0], location[1])\n",
    "        timestamp = location[2]\n",
    "        longitudes.append(longitude)\n",
    "        latitudes.append(latitude)\n",
    "        timestamps.append(timestamp)\n",
    "        location_names.append(location_name)\n",
    "        countries.append(country)\n",
    "        file_names.append(file)\n",
    "        categories.append(category)\n",
    "    else:\n",
    "        print(\"\\nNo geolocation information found in the photo.\" + file2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
